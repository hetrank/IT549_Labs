{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdgcVV_Pkssd",
        "outputId": "c85519a0-60b4-4c49-acfa-b26aa5ed26fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "655a08bb",
        "outputId": "405bd1be-3935-47d0-93eb-cce8c1e92323"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/fake_reviews_dataset.csv')\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             category  rating label  \\\n",
              "0  Home_and_Kitchen_5     5.0    CG   \n",
              "1  Home_and_Kitchen_5     5.0    CG   \n",
              "2  Home_and_Kitchen_5     5.0    CG   \n",
              "3  Home_and_Kitchen_5     1.0    CG   \n",
              "4  Home_and_Kitchen_5     5.0    CG   \n",
              "\n",
              "                                               text_  \n",
              "0  Love this!  Well made, sturdy, and very comfor...  \n",
              "1  love it, a great upgrade from the original.  I...  \n",
              "2  This pillow saved my back. I love the look and...  \n",
              "3  Missing information on how to use it, but it i...  \n",
              "4  Very nice set. Good quality. We have had the s...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f558c12a-9701-438c-bffe-e0bc9ecfa4fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>rating</th>\n",
              "      <th>label</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Home_and_Kitchen_5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>CG</td>\n",
              "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Home_and_Kitchen_5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>CG</td>\n",
              "      <td>love it, a great upgrade from the original.  I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Home_and_Kitchen_5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>CG</td>\n",
              "      <td>This pillow saved my back. I love the look and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Home_and_Kitchen_5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>CG</td>\n",
              "      <td>Missing information on how to use it, but it i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Home_and_Kitchen_5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>CG</td>\n",
              "      <td>Very nice set. Good quality. We have had the s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f558c12a-9701-438c-bffe-e0bc9ecfa4fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f558c12a-9701-438c-bffe-e0bc9ecfa4fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f558c12a-9701-438c-bffe-e0bc9ecfa4fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 40432,\n  \"fields\": [\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Toys_and_Games_5\",\n          \"Sports_and_Outdoors_5\",\n          \"Pet_Supplies_5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1443539194684442,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0,\n          4.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"OR\",\n          \"CG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40412,\n        \"samples\": [\n          \"It works well with my old ones, as long as you keep your hands on the handle and the other two fingers on the front of the switch.\",\n          \"I've not played the adult version of Cashflow so can't make a comparison but this game does a good job of teaching a basic tenet from the Rich Dad series: amass sources of passive income!  I bought this to play with my six year old because he's very interested in money and investing.  I thought this might be a good introduction to some basic concepts - and I believe it is a good introduction.  The instructions are not great, good enough but not great.  The instructions describe that you become a winner when your passive income exceeds your expenses - but there isn't really a winner of the game.  Small nuance but each individual \\\"wins\\\" by having passive income exceed expenses but the instructions don't state the first one to get there wins.\\n\\nEach player gets a \\\"financial statement\\\" as their game card.  During play, each player gains passive income sources and expenses.  The players keep track of their passive income vs expenses on the financial statement.  When your passive income exceeds expenses... you win!  The game does a good job of reinforcing this concept and also does a good job providing examples of passive income sources (rental property, owning a business, etc.).  It's at a pretty basic level so understandable for kids; even my six year old understands the game well enough to be able to formulate a strategy or predict what he needs on the next turn in order to win.\\n\\nWould recommend as a basic concept teaching tool.  And it's a fun game, too!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Preprocessing**"
      ],
      "metadata": {
        "id": "yU-suPFK_j3a"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3958eb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d1e6e4-ab6b-437f-e949-7305a0d739de"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "try:\n",
        "    # Explicitly download 'punkt_tab' as indicated by the error message\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    nltk.download('punkt_tab')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = ''.join([char for char in text if char not in string.punctuation])\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    processed_tokens = [\n",
        "        lemmatizer.lemmatize(word) for word in tokens if word not in stop_words\n",
        "    ]\n",
        "    return ' '.join(processed_tokens)\n",
        "\n",
        "df['preprocessed_review_text'] = df['text_'].apply(preprocess_text)\n",
        "\n",
        "print(df[['text_', 'preprocessed_review_text']].head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               text_  \\\n",
            "0  Love this!  Well made, sturdy, and very comfor...   \n",
            "1  love it, a great upgrade from the original.  I...   \n",
            "2  This pillow saved my back. I love the look and...   \n",
            "3  Missing information on how to use it, but it i...   \n",
            "4  Very nice set. Good quality. We have had the s...   \n",
            "\n",
            "                            preprocessed_review_text  \n",
            "0  love well made sturdy comfortable love itvery ...  \n",
            "1   love great upgrade original ive mine couple year  \n",
            "2            pillow saved back love look feel pillow  \n",
            "3        missing information use great product price  \n",
            "4                nice set good quality set two month  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fef1eee7",
        "outputId": "d5e50fe6-599d-402b-b997-8837b9db7290"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "X_text_features = tfidf_vectorizer.fit_transform(df['preprocessed_review_text'])\n",
        "\n",
        "print(X_text_features.shape)\n",
        "\n",
        "print(X_text_features[:5].toarray())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40432, 46248)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "uEkgdxpoyNvD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 1**"
      ],
      "metadata": {
        "id": "pwpg2rH2_P46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_text_features\n",
        "y = df['category']\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y_encoded, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "xKAHtUy3y23u"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, features, labels):\n",
        "\n",
        "    self.features = torch.tensor(features.toarray(), dtype=torch.float32).to(device)\n",
        "    self.labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    return self.features[index], self.labels[index]"
      ],
      "metadata": {
        "id": "vR3Y5SEsznPd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(X_train, y_train)"
      ],
      "metadata": {
        "id": "gtXiJdK60-gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CustomDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "U_zAFPX91dhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "K39Opm4F1lOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNN(nn.Module):\n",
        "\n",
        "  def __init__(self, num_features):\n",
        "\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(num_features, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 10),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    return self.model(x)"
      ],
      "metadata": {
        "id": "FrMuHIk416tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "RAsHCoCc2gEl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyNN(X_train.shape[1]).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr= learning_rate)"
      ],
      "metadata": {
        "id": "z6qZ0fV_2ipa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "  total_epoch_loss = 0\n",
        "\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    outputs = model(batch_features)\n",
        "\n",
        "    loss = criterion(outputs, batch_labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_epoch_loss = total_epoch_loss + loss.item()\n",
        "\n",
        "  avg_loss = total_epoch_loss/len(train_loader)\n",
        "  print(f'Epoch: {epoch + 1} , Loss: {avg_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg722RUB22B8",
        "outputId": "b7ce1205-34f3-4003-e3d3-f665781217b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 , Loss: 2.3025715487747798\n",
            "Epoch: 2 , Loss: 2.302226287574165\n",
            "Epoch: 3 , Loss: 2.3018881011857344\n",
            "Epoch: 4 , Loss: 2.301573870681491\n",
            "Epoch: 5 , Loss: 2.3012653985042344\n",
            "Epoch: 6 , Loss: 2.3009319140505884\n",
            "Epoch: 7 , Loss: 2.3006255640813955\n",
            "Epoch: 8 , Loss: 2.3002415966139482\n",
            "Epoch: 9 , Loss: 2.2997815806875117\n",
            "Epoch: 10 , Loss: 2.299134894793213\n",
            "Epoch: 11 , Loss: 2.2979805639138804\n",
            "Epoch: 12 , Loss: 2.295435478564779\n",
            "Epoch: 13 , Loss: 2.288070178785814\n",
            "Epoch: 14 , Loss: 2.266399923049414\n",
            "Epoch: 15 , Loss: 2.240172380986421\n",
            "Epoch: 16 , Loss: 2.22537504919904\n",
            "Epoch: 17 , Loss: 2.216307942103963\n",
            "Epoch: 18 , Loss: 2.206928984449786\n",
            "Epoch: 19 , Loss: 2.1926834244030737\n",
            "Epoch: 20 , Loss: 2.1752776977101806\n",
            "Epoch: 21 , Loss: 2.161098935858534\n",
            "Epoch: 22 , Loss: 2.151698087515096\n",
            "Epoch: 23 , Loss: 2.144968232147307\n",
            "Epoch: 24 , Loss: 2.1394035448669917\n",
            "Epoch: 25 , Loss: 2.132845640653678\n",
            "Epoch: 26 , Loss: 2.1233136055497783\n",
            "Epoch: 27 , Loss: 2.110540406977235\n",
            "Epoch: 28 , Loss: 2.0977992573274453\n",
            "Epoch: 29 , Loss: 2.0858636611535144\n",
            "Epoch: 30 , Loss: 2.0744945781504214\n",
            "Epoch: 31 , Loss: 2.061607698678028\n",
            "Epoch: 32 , Loss: 2.045552834456146\n",
            "Epoch: 33 , Loss: 2.029127305675401\n",
            "Epoch: 34 , Loss: 2.014538511221588\n",
            "Epoch: 35 , Loss: 2.0022087031202354\n",
            "Epoch: 36 , Loss: 1.9908384744357686\n",
            "Epoch: 37 , Loss: 1.9812986125116763\n",
            "Epoch: 38 , Loss: 1.971809785592226\n",
            "Epoch: 39 , Loss: 1.9629246722096982\n",
            "Epoch: 40 , Loss: 1.954540515134457\n",
            "Epoch: 41 , Loss: 1.9451071280735754\n",
            "Epoch: 42 , Loss: 1.934908501715528\n",
            "Epoch: 43 , Loss: 1.9214590222468018\n",
            "Epoch: 44 , Loss: 1.907497963886487\n",
            "Epoch: 45 , Loss: 1.8935507821000142\n",
            "Epoch: 46 , Loss: 1.881786564357667\n",
            "Epoch: 47 , Loss: 1.8718926956059905\n",
            "Epoch: 48 , Loss: 1.864806101020617\n",
            "Epoch: 49 , Loss: 1.8573463387168914\n",
            "Epoch: 50 , Loss: 1.8506617503675076\n",
            "Epoch: 51 , Loss: 1.8427406217269746\n",
            "Epoch: 52 , Loss: 1.8334567287693853\n",
            "Epoch: 53 , Loss: 1.8254799755665625\n",
            "Epoch: 54 , Loss: 1.8179272003324607\n",
            "Epoch: 55 , Loss: 1.8103206127057434\n",
            "Epoch: 56 , Loss: 1.8045364469878757\n",
            "Epoch: 57 , Loss: 1.7997527313326658\n",
            "Epoch: 58 , Loss: 1.7930738532496064\n",
            "Epoch: 59 , Loss: 1.7889670376249924\n",
            "Epoch: 60 , Loss: 1.7838086306813206\n",
            "Epoch: 61 , Loss: 1.7806301691786575\n",
            "Epoch: 62 , Loss: 1.7761370461920034\n",
            "Epoch: 63 , Loss: 1.7725783145946006\n",
            "Epoch: 64 , Loss: 1.7698380662047344\n",
            "Epoch: 65 , Loss: 1.7661404079599343\n",
            "Epoch: 66 , Loss: 1.7632184266572883\n",
            "Epoch: 67 , Loss: 1.7609693410368306\n",
            "Epoch: 68 , Loss: 1.7581025206524392\n",
            "Epoch: 69 , Loss: 1.7560754069697715\n",
            "Epoch: 70 , Loss: 1.7541625671707124\n",
            "Epoch: 71 , Loss: 1.7511654717648926\n",
            "Epoch: 72 , Loss: 1.7502879260085789\n",
            "Epoch: 73 , Loss: 1.747818893594704\n",
            "Epoch: 74 , Loss: 1.7466727290228892\n",
            "Epoch: 75 , Loss: 1.7448138453272493\n",
            "Epoch: 76 , Loss: 1.7435673133657854\n",
            "Epoch: 77 , Loss: 1.742080745489701\n",
            "Epoch: 78 , Loss: 1.7412904684722659\n",
            "Epoch: 79 , Loss: 1.7393798726820664\n",
            "Epoch: 80 , Loss: 1.7387100587720457\n",
            "Epoch: 81 , Loss: 1.737179324089774\n",
            "Epoch: 82 , Loss: 1.7365830802163589\n",
            "Epoch: 83 , Loss: 1.7354119655643057\n",
            "Epoch: 84 , Loss: 1.7343839800404937\n",
            "Epoch: 85 , Loss: 1.7338680869976995\n",
            "Epoch: 86 , Loss: 1.7326658292721382\n",
            "Epoch: 87 , Loss: 1.7319052151069338\n",
            "Epoch: 88 , Loss: 1.7313782075648252\n",
            "Epoch: 89 , Loss: 1.73079649049774\n",
            "Epoch: 90 , Loss: 1.729875322151561\n",
            "Epoch: 91 , Loss: 1.7290540368189453\n",
            "Epoch: 92 , Loss: 1.728449342279095\n",
            "Epoch: 93 , Loss: 1.7284052284809912\n",
            "Epoch: 94 , Loss: 1.727385507977527\n",
            "Epoch: 95 , Loss: 1.7269336176012815\n",
            "Epoch: 96 , Loss: 1.7264583468908379\n",
            "Epoch: 97 , Loss: 1.7258671284193108\n",
            "Epoch: 98 , Loss: 1.7252126574045112\n",
            "Epoch: 99 , Loss: 1.725229005332992\n",
            "Epoch: 100 , Loss: 1.724736250436353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK0JajZr5-jB",
        "outputId": "541d768e-d255-42e5-e106-9aaf38f46bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyNN(\n",
              "  (model): Sequential(\n",
              "    (0): Linear(in_features=46248, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
              "    (5): Softmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch_features, batch_labels in test_loader:\n",
        "\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    outputs = model(batch_features)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    total = total + batch_labels.shape[0]\n",
        "\n",
        "    correct = correct + (predicted == batch_labels).sum().item()\n",
        "\n",
        "print('Accuracy:')\n",
        "print(correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ6P-xEs6CtP",
        "outputId": "7888dec1-7259-473a-900f-5b23a74d2810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:\n",
            "0.5958946457277111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 2**"
      ],
      "metadata": {
        "id": "XK7keJ3c_b70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_text_features\n",
        "y = df['label']\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X,y_encoded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "wjaJxQWW665a"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edef3dc1"
      },
      "source": [
        "class MyNN_Binary(nn.Module):\n",
        "\n",
        "  def __init__(self, num_features):\n",
        "\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(num_features, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    return self.model(x)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32ec06db"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, features, labels):\n",
        "\n",
        "    self.features = torch.tensor(features.toarray(), dtype=torch.float32).to(device)\n",
        "    # For binary classification, labels need to be float32 and reshaped to (batch_size, 1)\n",
        "    self.labels = torch.tensor(labels, dtype=torch.float32).to(device).unsqueeze(1)\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    return self.features[index], self.labels[index]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3b355a8"
      },
      "source": [
        "model = MyNN_Binary(X_train.shape[1]).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr= learning_rate)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0507bcf"
      },
      "source": [
        "train_dataset_1 = CustomDataset(X_train_1, y_train_1)\n",
        "test_dataset_1 = CustomDataset(X_test_1, y_test_1)\n",
        "\n",
        "train_loader_1 = DataLoader(train_dataset_1, batch_size=64, shuffle=True)\n",
        "test_loader_1 = DataLoader(test_dataset_1, batch_size=64, shuffle=False)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44ec9a03",
        "outputId": "dbb53bd3-2f9f-4a7e-90a5-af5459a2bf24"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "  total_epoch_loss = 0\n",
        "\n",
        "  for batch_features, batch_labels in train_loader_1:\n",
        "\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    outputs = model(batch_features)\n",
        "\n",
        "    loss = criterion(outputs, batch_labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_epoch_loss = total_epoch_loss + loss.item()\n",
        "\n",
        "  avg_loss = total_epoch_loss/len(train_loader_1)\n",
        "  print(f'Epoch: {epoch + 1} , Loss: {avg_loss}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 , Loss: 0.6927388910012754\n",
            "Epoch: 2 , Loss: 0.6893710199552091\n",
            "Epoch: 3 , Loss: 0.6358637653085083\n",
            "Epoch: 4 , Loss: 0.4404823963232191\n",
            "Epoch: 5 , Loss: 0.37874047393384186\n",
            "Epoch: 6 , Loss: 0.3410692724726888\n",
            "Epoch: 7 , Loss: 0.3138420886614106\n",
            "Epoch: 8 , Loss: 0.29624782679344824\n",
            "Epoch: 9 , Loss: 0.2863330152990083\n",
            "Epoch: 10 , Loss: 0.2562886918692485\n",
            "Epoch: 11 , Loss: 0.2621472831741859\n",
            "Epoch: 12 , Loss: 0.2469413351606239\n",
            "Epoch: 13 , Loss: 0.23394475158730985\n",
            "Epoch: 14 , Loss: 0.23806942567936046\n",
            "Epoch: 15 , Loss: 0.21735098782794277\n",
            "Epoch: 16 , Loss: 0.21634111281027907\n",
            "Epoch: 17 , Loss: 0.21185265581598395\n",
            "Epoch: 18 , Loss: 0.20022966982170998\n",
            "Epoch: 19 , Loss: 0.2057601083806263\n",
            "Epoch: 20 , Loss: 0.187561327451656\n",
            "Epoch: 21 , Loss: 0.1750423485199689\n",
            "Epoch: 22 , Loss: 0.17362628411869757\n",
            "Epoch: 23 , Loss: 0.18738636455458144\n",
            "Epoch: 24 , Loss: 0.17329097118066705\n",
            "Epoch: 25 , Loss: 0.17522425875583067\n",
            "Epoch: 26 , Loss: 0.18236909122776843\n",
            "Epoch: 27 , Loss: 0.15550422930920665\n",
            "Epoch: 28 , Loss: 0.1512702193641262\n",
            "Epoch: 29 , Loss: 0.13723779604457348\n",
            "Epoch: 30 , Loss: 0.1969751666185884\n",
            "Epoch: 31 , Loss: 0.13719771281547344\n",
            "Epoch: 32 , Loss: 0.14370317253552878\n",
            "Epoch: 33 , Loss: 0.12025862452371613\n",
            "Epoch: 34 , Loss: 0.13773585113479567\n",
            "Epoch: 35 , Loss: 0.12041873005384454\n",
            "Epoch: 36 , Loss: 0.13399839424436152\n",
            "Epoch: 37 , Loss: 0.08569153354470084\n",
            "Epoch: 38 , Loss: 0.07550473746442395\n",
            "Epoch: 39 , Loss: 0.05938731478122265\n",
            "Epoch: 40 , Loss: 0.200501581681561\n",
            "Epoch: 41 , Loss: 0.12971791643244418\n",
            "Epoch: 42 , Loss: 0.09225617972728999\n",
            "Epoch: 43 , Loss: 0.12574520947139253\n",
            "Epoch: 44 , Loss: 0.06405280031845445\n",
            "Epoch: 45 , Loss: 0.04136367099867626\n",
            "Epoch: 46 , Loss: 0.06618094937176455\n",
            "Epoch: 47 , Loss: 0.21178799289326541\n",
            "Epoch: 48 , Loss: 0.07790823747208821\n",
            "Epoch: 49 , Loss: 0.05574612063355744\n",
            "Epoch: 50 , Loss: 0.17776037284022145\n",
            "Epoch: 51 , Loss: 0.08487699740095131\n",
            "Epoch: 52 , Loss: 0.026936513858593324\n",
            "Epoch: 53 , Loss: 0.056147997578598646\n",
            "Epoch: 54 , Loss: 0.017329015807486085\n",
            "Epoch: 55 , Loss: 0.013046978053953426\n",
            "Epoch: 56 , Loss: 0.010984247414857193\n",
            "Epoch: 57 , Loss: 0.009122179985863595\n",
            "Epoch: 58 , Loss: 0.007637807832047962\n",
            "Epoch: 59 , Loss: 0.006453678946322743\n",
            "Epoch: 60 , Loss: 0.005599611032622583\n",
            "Epoch: 61 , Loss: 0.005078771673860728\n",
            "Epoch: 62 , Loss: 0.004479163511414191\n",
            "Epoch: 63 , Loss: 0.0040084231228902645\n",
            "Epoch: 64 , Loss: 0.0035732293907799594\n",
            "Epoch: 65 , Loss: 0.003294544129746528\n",
            "Epoch: 66 , Loss: 0.002970278536587523\n",
            "Epoch: 67 , Loss: 0.0029427267977067827\n",
            "Epoch: 68 , Loss: 0.0025759548429223037\n",
            "Epoch: 69 , Loss: 0.0024201736444162884\n",
            "Epoch: 70 , Loss: 0.0022344781625822643\n",
            "Epoch: 71 , Loss: 0.0020502645011831132\n",
            "Epoch: 72 , Loss: 0.0018700832138003657\n",
            "Epoch: 73 , Loss: 0.0017249966911067854\n",
            "Epoch: 74 , Loss: 0.0015943443018776502\n",
            "Epoch: 75 , Loss: 0.0015074923855281093\n",
            "Epoch: 76 , Loss: 0.0014125565137680098\n",
            "Epoch: 77 , Loss: 0.001332562399162817\n",
            "Epoch: 78 , Loss: 0.0012806525470375125\n",
            "Epoch: 79 , Loss: 0.0011936754902850987\n",
            "Epoch: 80 , Loss: 0.0011495864349810809\n",
            "Epoch: 81 , Loss: 0.0010892580020132846\n",
            "Epoch: 82 , Loss: 0.0010406245919979333\n",
            "Epoch: 83 , Loss: 0.0010063509901595787\n",
            "Epoch: 84 , Loss: 0.0009617309639400162\n",
            "Epoch: 85 , Loss: 0.0009482847428602247\n",
            "Epoch: 86 , Loss: 0.0008889200601447466\n",
            "Epoch: 87 , Loss: 0.0008558998721386693\n",
            "Epoch: 88 , Loss: 0.0008169172449659081\n",
            "Epoch: 89 , Loss: 0.0007813023646729547\n",
            "Epoch: 90 , Loss: 0.0007662742934799422\n",
            "Epoch: 91 , Loss: 0.0007330871520694179\n",
            "Epoch: 92 , Loss: 0.0007089095653125394\n",
            "Epoch: 93 , Loss: 0.0006878289563239464\n",
            "Epoch: 94 , Loss: 0.0006700564793179\n",
            "Epoch: 95 , Loss: 0.000646638170976593\n",
            "Epoch: 96 , Loss: 0.0006245979619505327\n",
            "Epoch: 97 , Loss: 0.000605349235405516\n",
            "Epoch: 98 , Loss: 0.0005862707297738482\n",
            "Epoch: 99 , Loss: 0.0005722608752426758\n",
            "Epoch: 100 , Loss: 0.0005730253646818354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "add77dfd",
        "outputId": "4bfb0f6c-56ea-4fe8-ece8-14442c0d130a"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch_features, batch_labels in test_loader_1:\n",
        "\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    outputs = model(batch_features)\n",
        "\n",
        "    predicted = (outputs > 0.5).float() # Threshold at 0.5 for binary classification\n",
        "\n",
        "    total = total + batch_labels.shape[0]\n",
        "\n",
        "    correct = correct + (predicted == batch_labels).sum().item()\n",
        "\n",
        "print('Accuracy:')\n",
        "print(correct/total)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:\n",
            "0.8889575862495362\n"
          ]
        }
      ]
    }
  ]
}